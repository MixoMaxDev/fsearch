{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# scrape topic index\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install chromadb\n",
    "%pip install bs4\n",
    "%pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#only run if using gpu\n",
    "%pip install tensorflow-gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if not using gpu\n",
    "%pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install tensorflow_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "import chromadb\n",
    "from bs4 import BeautifulSoup\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if using a remote session, download the gzipped wiki dump\n",
    "url = \"https://dumps.wikimedia.org/enwiki/latest/enwiki-latest-all-titles-in-ns0.gz\"\n",
    "\n",
    "#download the file\n",
    "r = requests.get(url, stream = True)\n",
    "\n",
    "#save the file\n",
    "with open(\"enwiki-latest-all-titles-in-ns0.gz\", \"wb\") as f:\n",
    "    for chunk in r.iter_content(chunk_size = 1024):\n",
    "        if chunk:\n",
    "            f.write(chunk)\n",
    "\n",
    "#unzip the file to ./data/\n",
    "!gunzip -k enwiki-latest-all-titles-in-ns0.gz\n",
    "\n",
    "#copy and rename the file to ./data/enwiki-latest-all-titles.txt\n",
    "!cp enwiki-latest-all-titles-in-ns0 enwiki-latest-all-titles.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load wikipedia article titles\n",
    "\n",
    "wiki_titles = []\n",
    "with open(\"./data/enwiki-latest-all-titles.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        line = line.strip()\n",
    "        line = line.replace(\"_\", \" \")\n",
    "        wiki_titles.append(line)\n",
    "\n",
    "print(len(wiki_titles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tell tensorflow to use GPU\n",
    "#GPU 0 is GTX 1050 Ti\n",
    "\n",
    "devices = tf.config.experimental.list_physical_devices(\"GPU\")\n",
    "\n",
    "print(devices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_ef(text):\n",
    "    embeddings = embed(text)\n",
    "    \n",
    "    #flatten tensor to list\n",
    "    embeddings = np.array(embeddings).flatten().tolist()\n",
    "    \n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_to_str(t: int):\n",
    "    \"\"\"Converts time in seconds to the appropriate time unit\"\"\"\n",
    "    \n",
    "    if t > 3600 * 24:\n",
    "        out_str = f\"{round(t / (3600 * 24), 2)} days\"\n",
    "    elif t > 3600:\n",
    "        out_str = f\"{round(t / 3600, 2)} hours\"\n",
    "    elif t > 60:\n",
    "        out_str = f\"{round(t / 60, 2)} minutes\"\n",
    "    elif 60 > t > 1:\n",
    "        out_str = f\"{round(t, 2)} seconds\"\n",
    "    elif t < 1:\n",
    "        out_str = f\"{round(t * 1000, 2)} milliseconds\"\n",
    "    else:\n",
    "        out_str = f\"{round(t, 2)} seconds\"\n",
    "    \n",
    "    return out_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10000\n",
    "batches = [\n",
    "    wiki_titles[i:i + batch_size] for i in range(0, len(wiki_titles), batch_size)\n",
    "]\n",
    "\n",
    "#for each batch, get the embeddings\n",
    "#save the embeddings to disk in a .npy file\n",
    "\n",
    "if not os.path.exists(\"./content/embeddings\"):\n",
    "    os.makedirs(\"./content/embeddings\")\n",
    "\n",
    "for i, batch in enumerate(batches):\n",
    "    print(f\"Processing batch {i + 1} of {len(batches)}\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    embeddings = embed(batch)\n",
    "    \n",
    "    #flatten tensor to list\n",
    "    embeddings_np = np.array(embeddings)\n",
    "    \n",
    "    np.save(f\"./content/embeddings/batch_{i}.npy\", embeddings)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    \n",
    "    batches_left = len(batches) - i - 1\n",
    "    time_remaining = batches_left * (end_time - start_time)\n",
    "    \n",
    "    print(\n",
    "        f\"Batch {i + 1}/{len(batches)} complete. Time remaining: {time_to_str(time_remaining)}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#delete embeddings from disk\n",
    "file_path = \"./content/embeddings\"\n",
    "for file in os.listdir(file_path):\n",
    "    os.remove(os.path.join(file_path, file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the embeddings from disk\n",
    "#concatenate the embeddings into one large array\n",
    "#convert the np array to a list\n",
    "\n",
    "embeddings = []\n",
    "file_path = \"./content/embeddings\"\n",
    "\n",
    "for idx, file in enumerate(os.listdir(file_path)):\n",
    "    print(f\"Loading file {idx + 1} of {len(os.listdir(file_path))}\")\n",
    "    embeddings.append(np.load(f\"{file_path}/{file}\"))\n",
    "\n",
    "embeddings = np.concatenate(embeddings).tolist()\n",
    "\n",
    "print(len(embeddings))\n",
    "print(type(embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Client = chromadb.PersistentClient(\"./data/chromadb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#delete collection \"wiki_titles\"\n",
    "\n",
    "Client.delete_collection(\"wiki_titles\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add wikipedia article titles to chromadb\n",
    "\n",
    "collection = Client.get_or_create_collection(\"wiki_titles\")\n",
    "\n",
    "batch_size = 1000\n",
    "batches = [\n",
    "    embeddings[i:i + batch_size] for i in range(0, len(embeddings), batch_size)\n",
    "]\n",
    "\n",
    "for i, batch in enumerate(batches):\n",
    "    print(f\"Processing batch {i + 1} of {len(batches)}\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    collection.add(\n",
    "        embeddings=batch,\n",
    "        documents=wiki_titles[i * batch_size:(i + 1) * batch_size],\n",
    "        metadatas=None,\n",
    "        ids = [str(i) for i in range(i * batch_size, (i + 1) * batch_size)]\n",
    "    )\n",
    "    \n",
    "    end_time = time.time()\n",
    "    \n",
    "    batches_left = len(batches) - i - 1\n",
    "    time_remaining = batches_left * (end_time - start_time)\n",
    "    \n",
    "    print(\n",
    "        f\"Batch {i + 1}/{len(batches)} complete. Time remaining: {time_to_str(time_remaining)}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query(query: str, num_results: int = 10):\n",
    "    collection = Client.get_collection(\"wiki_titles\")\n",
    "    \n",
    "    t_start = time.time()\n",
    "    \n",
    "    embeddings = custom_ef([query])\n",
    "    \n",
    "    r = collection.query(\n",
    "        query_embeddings=embeddings,\n",
    "        n_results=num_results\n",
    "    )\n",
    "    \n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query(\"Belgium\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
